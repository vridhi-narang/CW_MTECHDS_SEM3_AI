{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "MTECH_DS_VridhiNarang_D020.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vridhi-narang/CW_MTECHDS_SEM3_AI/blob/master/MTECH_DS_VridhiNarang_D020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b357fa29ec56d7bc265d3ff641ed56eb84090f6d",
        "id": "A_eQBvUbHvT8",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='1'>1. Problem Statement</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cd0ff3f769b834bada40a5fe4f013d6a479d1869",
        "id": "QRZ-IBfWHvT9",
        "colab_type": "text"
      },
      "source": [
        "Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.\n",
        "\n",
        "**Evalutaion**  - Area under the ROC Curve\n",
        "\n",
        "**Data  ** -   the problem has 7 files. \n",
        "\n",
        "* **application_train/application_test**: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR.  \n",
        "* **bureau **: All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample). Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "C7KSeX8NHvT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "# import for plotting \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5dd1eaae5623c9ecdf8fde81b505b4ed293e049b",
        "id": "FSfvNTGQHvUB",
        "colab_type": "text"
      },
      "source": [
        ">  # <a id='2'>2. Reading the Data</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "-WPHiDJoHvUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app_train = pd.read_csv('../input/application_train.csv')\n",
        "app_test = pd.read_csv('../input/application_test.csv')\n",
        "bureau = pd.read_csv('../input/bureau.csv')\n",
        "bureau_balance = pd.read_csv('../input/bureau_balance.csv')\n",
        "pos_cash_balance = pd.read_csv('../input/POS_CASH_balance.csv')\n",
        "\n",
        "previous_app = pd.read_csv('../input/previous_application.csv')\n",
        "installments_payments = pd.read_csv('../input/installments_payments.csv')\n",
        "credit_card_balance = pd.read_csv('../input/credit_card_balance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "47a6124df95306a1b400f19aa01402ecb62cf566",
        "id": "8eCBg_GfHvUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(app_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "77f0b6f1ff903279cd7c012897d71c5527605ca7",
        "id": "9bCDSbReHvUH",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='3'>3. Feature Engineering</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1abd668104bee54e84b172693b6783c22fcca178",
        "id": "Qn0QQ3EtHvUH",
        "colab_type": "text"
      },
      "source": [
        "## <a id='3-1'>3.1 Creating new feature for bureau</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d74d5a5f546adea6bbfd50f5526028203e59542a",
        "id": "VpcYCtoGHvUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Groupby the client id (SK_ID_CURR), count the number of previous loans, and rename the column\n",
        "previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\n",
        "previous_loan_counts.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "835f505d2f0d2c902ba1ffd299854abe3c7ceb94",
        "id": "xJ0N-eF_HvUK",
        "colab_type": "text"
      },
      "source": [
        "## <a id='3-2'>3.2 Function to count and normalize values of categorical variables </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8a2e9b38eb335eb43bb08a82002566b082e1e1bc",
        "id": "X0R3sr0hHvUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_categorical(df, group_var, col_name):\n",
        "    \n",
        "    \"\"\"Computes counts and normalized counts for each observation\n",
        "    of `group_var` for each unique category in every categorical variable\n",
        "    \n",
        "    Parameters \n",
        "    ----------\n",
        "    df - DataFrame for which we will calculate count\n",
        "    \n",
        "    group_var  = string\n",
        "        The variable by which to group the dataframe. For each unique\n",
        "        value of this variable, the final dataframe will have one row\n",
        "        \n",
        "    col_name = string\n",
        "            Variable added to the front of column names to keep track of columns\n",
        "            \n",
        "            \"\"\"\n",
        "    # select the categorical columns\n",
        "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
        "    \n",
        "    # Make sure to put the identifying id on the column\n",
        "    categorical[group_var] = df[group_var]\n",
        "    \n",
        "    # Groupby the group var and calculate the sum and mean\n",
        "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])                                              \n",
        "    \n",
        "    column_names = []\n",
        "    \n",
        "    # Iterate through the columns in level 0\n",
        "    for var in categorical.columns.levels[0]:\n",
        "        # Iterate through the stats in level 1\n",
        "        for stat in ['count', 'count_norm']:\n",
        "            # Make a new column name\n",
        "            column_names.append('%s_%s_%s' % (col_name, var, stat))\n",
        "    \n",
        "    categorical.columns = column_names\n",
        "    \n",
        "    return categorical\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "593480adaaa613827e7c2ed8ed9fb2976c49606b",
        "id": "cCnbaV1FHvUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bureau_counts = normalize_categorical(bureau, group_var = 'SK_ID_CURR', col_name = 'bureau')\n",
        "bureau_counts.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c2b47c5a19e1bdeb1425ae89a39349de38702f09",
        "id": "nbX-wLQEHvUQ",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='4'>4 Grouping the data </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "619f4b8f739cb4132746c3f9943b8045f607e609",
        "id": "4PWDMPm2HvUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grouping data  so  that we can merge all the files in 1 dataset\n",
        "\n",
        "data_bureau_agg=bureau.groupby(by='SK_ID_CURR').mean()\n",
        "data_credit_card_balance_agg=credit_card_balance.groupby(by='SK_ID_CURR').mean()\n",
        "data_previous_application_agg=previous_app.groupby(by='SK_ID_CURR').mean()\n",
        "data_installments_payments_agg=installments_payments.groupby(by='SK_ID_CURR').mean()\n",
        "data_POS_CASH_balance_agg=pos_cash_balance.groupby(by='SK_ID_CURR').mean()\n",
        "\n",
        "data_bureau_agg.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "535c94e68729c98ea2341d1e586aa88fea61d118",
        "id": "dzXIVqSFHvUd",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='6'>6. Merging the data</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "31caadcce9dca883497da8bf6ed221a1f5f41530",
        "id": "SaKLrAuiHvUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge(df):\n",
        "    df = df.join(data_bureau_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2') \n",
        "    df = df.join(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
        "    df = df.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n",
        "    df = df.join(data_credit_card_balance_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2')    \n",
        "    df = df.join(data_previous_application_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2')   \n",
        "    df = df.join(data_installments_payments_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2') \n",
        "    \n",
        "    return df\n",
        "\n",
        "train = merge(app_train)\n",
        "test = merge(app_test)\n",
        "display(train.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "115ce085078c451ad9c38bd2079c000eb6701363",
        "id": "XGEQ1T6FHvUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7d99f241fd2e9f1b6de96df8d8f468953bcf7c3e",
        "id": "djIlt3rLHvUj",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='7'>7. Combining training and testing data</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8a960e0285293edccb5fe58db4ff66944ce1525f",
        "id": "An0iTr1tHvUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combining the data\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "\n",
        "y_train = train.TARGET.values\n",
        "\n",
        "#train_df = train_df.drop\n",
        "\n",
        "all_data = pd.concat([train, test]).reset_index(drop=True)\n",
        "all_data.drop(['TARGET'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a84b333d3fd460b2415abfbdedd294535da72a74",
        "id": "pysLDmHhHvUn",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='8'>8. Feature Engineering Continued</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8c5602d4fc8e82589dda908c26e35f6d771f1e55",
        "id": "eTkedsLiHvUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we will convert days employed and days registration and days id publish to a positive no. \n",
        "def correct_birth(df):\n",
        "    \n",
        "    df['DAYS_BIRTH'] = round((df['DAYS_BIRTH'] * (-1))/365)\n",
        "    return df\n",
        "\n",
        "def convert_abs(df):\n",
        "    df['DAYS_EMPLOYED'] = abs(df['DAYS_EMPLOYED'])\n",
        "    df['DAYS_REGISTRATION'] = abs(df['DAYS_REGISTRATION'])\n",
        "    df['DAYS_ID_PUBLISH'] = abs(df['DAYS_ID_PUBLISH'])\n",
        "    df['DAYS_LAST_PHONE_CHANGE'] = abs(df['DAYS_LAST_PHONE_CHANGE'])\n",
        "    return df\n",
        "\n",
        "# Now we will fill misisng values in OWN_CAR_AGE. \n",
        "#Most probably there will be missing values if the person does not own a car. So we will fill with 0\n",
        "\n",
        "def missing(df):\n",
        "    \n",
        "    features = ['previous_loan_counts','NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAPARTMENTS_AVG','NONLIVINGAREA_MEDI','OWN_CAR_AGE']\n",
        "    \n",
        "    for f in features:\n",
        "        df[f] = df[f].fillna(0 )\n",
        "    return df\n",
        "\n",
        "def transform_app(df):\n",
        "    df = correct_birth(df)\n",
        "    df = convert_abs(df)\n",
        "    df = missing(df)\n",
        "    return df\n",
        "\n",
        "   \n",
        "\n",
        "all_data = transform_app(all_data)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3a6055689140c328f7a64395af2fe717202f33eb",
        "id": "OABA6bjnHvUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# counting no of phones given by the company and delete the irrelevant features\n",
        "all_data['NO_OF_CLIENT_PHONES'] = all_data['FLAG_MOBIL'] + all_data['FLAG_EMP_PHONE'] + all_data['FLAG_WORK_PHONE']\n",
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "927d152f15996c3fa2c72f8a9fcc824e15b5fef5",
        "id": "PceBHhRcHvUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a feature to determine if client's permanent city does not match with contact/work city\n",
        "all_data['FLAG_CLIENT_OUTSIDE_CITY'] = np.where((all_data['REG_CITY_NOT_WORK_CITY']==1) & (all_data['REG_CITY_NOT_LIVE_CITY']==1),1,0)\n",
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "1f907d1d7e4ed526dbdf62ed88005a9d9ac962ee",
        "id": "KT8Xsa80HvUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # add a feature to determine if client's permanent city does not match with contact/work region\n",
        "all_data['FLAG_CLIENT_OUTSIDE_REGION'] = np.where((all_data['REG_REGION_NOT_LIVE_REGION']==1) & (all_data['REG_REGION_NOT_WORK_REGION']==1),1,0)\n",
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0dafd2c1e4b2c5c60114e80daca7753c0fa8bfea",
        "id": "jtDi4aF9HvUx",
        "colab_type": "text"
      },
      "source": [
        " ## <a id='8'>8.1. Deleting features</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0911e041f374a471ed1f6d5fe8fffefcf098cd29",
        "id": "58XwApYIHvUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deleting useless features\n",
        "def delete(df):\n",
        "   # useless=['FLAG_MOBIL', 'FLAG_EMP_PHONE' ,'FLAG_WORK_PHONE','REG_CITY_NOT_WORK_CITY','REG_CITY_NOT_LIVE_CITY','REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION']\n",
        "    #for feature in useless:\n",
        "     return df.drop(['FLAG_MOBIL', 'FLAG_EMP_PHONE' ,'FLAG_WORK_PHONE','REG_CITY_NOT_WORK_CITY','REG_CITY_NOT_LIVE_CITY','REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION'], axis=1)\n",
        "def transform(df):\n",
        "   # df = convert_abs(df)\n",
        "    df = delete(df)\n",
        "   \n",
        "    return df\n",
        "\n",
        "all_data = transform(all_data)\n",
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d77a960c80551da5257053276c073605b2856466",
        "id": "soH0nMVEHvUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete Ids\n",
        "\n",
        "def delete_id(df):\n",
        "    return df.drop(['SK_ID_CURR', 'SK_ID_PREV','SK_ID_BUREAU'], axis = 1)\n",
        "\n",
        "all_data = delete_id(all_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "36434d8ca67b47ac64657e604d7c09c7c265ee71",
        "id": "2ihnVwQ3HvU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ff9cde80e7b8c2412ce3adde81d1364544097991",
        "id": "fN6MSW_WHvU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(all_data.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "602f6ec0c36bcbc407ea70ccaea169680005c417",
        "id": "IgrK1ioCHvU5",
        "colab_type": "text"
      },
      "source": [
        "## <a id='8-2'>8.2  Handling Missing Values </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "91e4ff918f45d5e84fc0e5f2acf18702d74d7475",
        "id": "H8J5lBexHvU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# handling missing values\n",
        "\n",
        "def miss_numerical(df):\n",
        "    \n",
        "    features = ['previous_loan_counts','NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAPARTMENTS_AVG','NONLIVINGAREA_MEDI','OWN_CAR_AGE']\n",
        "    numerical_features = all_data.select_dtypes(exclude = [\"object\"] ).columns\n",
        "    #print(numerical_features)\n",
        "    for f in numerical_features:\n",
        "        #print(f)\n",
        "        if f not in features:\n",
        "            df[f] = df[f].fillna(df[f].median())\n",
        "      \n",
        "    return df\n",
        "\n",
        "def miss_categorical(df):\n",
        "    \n",
        "    categorical_features = all_data.select_dtypes(include = [\"object\"]).columns\n",
        "    \n",
        "    for f in categorical_features:\n",
        "        df[f] = df[f].fillna(df[f].mode()[0])\n",
        "        \n",
        "    return df\n",
        "\n",
        "def transform_feature(df):\n",
        "    df = miss_numerical(df)\n",
        "    df = miss_categorical(df)\n",
        "    #df = fill_cabin(df)\n",
        "    return df\n",
        "\n",
        "all_data = transform_feature(all_data)\n",
        "\n",
        "\n",
        "all_data.head()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5349f37ffa0b641d1f20c85b9ccb6fe3749ed23a",
        "id": "KME5LT22HvU8",
        "colab_type": "text"
      },
      "source": [
        "## <a id='8-3'>8.3 Scaling Numerical Features </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "dec691cd4fdb5c642e4f354845cca052fae95167",
        "id": "7wGBKrPEHvU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling the data \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def encoder(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    numerical = all_data.select_dtypes(exclude = [\"object\"]).columns\n",
        "    features_transform = pd.DataFrame(data= df)\n",
        "    features_transform[numerical] = scaler.fit_transform(df[numerical])\n",
        "    display(features_transform.head(n = 5))\n",
        "    return df\n",
        "\n",
        "all_data = encoder(all_data)\n",
        "\n",
        "#display(all_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1bf4a405c94494e409011e7f6838fb86a0e75a47",
        "id": "HfHO1h5THvU_",
        "colab_type": "text"
      },
      "source": [
        "## <a id='8-4'>8.4 Converting into categorical features </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ce8d7adace8a63ef075bde2c716e91881edca026",
        "id": "6kunfShEHvU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting into categorical features\n",
        "\n",
        "# Create a label encoder object\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le_count = 0\n",
        "\n",
        "\n",
        "# Iterate through the columns\n",
        "for col in all_data:\n",
        "    if all_data[col].dtype == 'object':\n",
        "        # If 2 or fewer unique categories\n",
        "        if len(list(all_data[col].unique())) <= 2:\n",
        "            # Train on the training data\n",
        "            le.fit(all_data[col])\n",
        "            # Transform both training and testing data\n",
        "            all_data[col] = le.transform(all_data[col])\n",
        "            #test[col] = le.transform(test[col])\n",
        "            \n",
        "            # Keep track of how many columns were label encoded\n",
        "            le_count += 1\n",
        "           \n",
        "print('%d columns were label encoded.' % le_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "48ed76f0cc7b3bf6df16b4c0d44f6ba53139a139",
        "id": "qofJubrxHvVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dummy variables\n",
        "all_data = pd.get_dummies(all_data)\n",
        "\n",
        "display(all_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c2065b7b588b7bf69df8b6adeb37d91a9c3de79b",
        "id": "5ThVGaDiHvVD",
        "colab_type": "text"
      },
      "source": [
        "> # <a id='9'>9. Modelling</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0624780a1f480762332a7de5098ffc2f928a6d62",
        "id": "xxEXYsH0HvVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Splitting features\n",
        "train = all_data[:ntrain]\n",
        "test = all_data[ntrain:]\n",
        "\n",
        "print(\"Training shape\", train.shape)\n",
        "print(\"Testing shape\", test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "1368520ec18e921a4802757c6ca213168b242392",
        "id": "X2gwUumhHvVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(train, y_train, test_size = 0.3, random_state = 200)\n",
        "print(\"X Training shape\", X_train.shape)\n",
        "print(\"X Testing shape\", X_test.shape)\n",
        "print(\"Y Training shape\", Y_train.shape)\n",
        "print(\"Y Testing shape\", Y_test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "bc839f8b1ab54603dfbe2c95681e895eee8700b5",
        "id": "ztWwYcRpHvVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "\n",
        "logreg = LogisticRegression(random_state=0, class_weight='balanced', C=100)\n",
        "logreg.fit(X_train, Y_train)\n",
        "Y_pred = logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "#Y_pred_proba = logreg.predict_proba(X_test)\n",
        "\n",
        "print('Train/Test split results:')\n",
        "#print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(Y_test, Y_pred))\n",
        "print(\"ROC\",  roc_auc_score(Y_test, Y_pred))\n",
        "#print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b4cbdcd721b0b7225e2be3c96893ea08d4e319dc",
        "id": "wRhesm9FHvVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_test = logreg.predict_proba(test)\n",
        "#print(\"ROC\",  roc_auc_score(Y_test, pred_test))\n",
        "submission = pd.read_csv('../input/sample_submission.csv')\n",
        "\n",
        "submission['SK_ID_CURR']=app_test['SK_ID_CURR']\n",
        "print(len(app_test['SK_ID_CURR']))\n",
        "submission['TARGET']=pred_test\n",
        "#converting to csv\n",
        "#print(submission['TARGET'])\n",
        "pd.DataFrame(submission, columns=['SK_ID_CURR','TARGET'],index=None).to_csv('homecreditada.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}